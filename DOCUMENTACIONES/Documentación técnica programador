# Documentación Técnica del Analizador de Noticias con IA

## 1. Objetivo del Proyecto

Este proyecto es una aplicación de línea de comandos en Python diseñada para recolectar noticias de fuentes públicas, analizarlas utilizando modelos de Procesamiento de Lenguaje Natural (NLP) y generar informes de salida tanto visuales (gráficos) como tabulares (CSV).

---

## 2. Tecnologías y Arquitectura

### 2.1. Stack Tecnológico
- **Lenguaje:** Python 3.11
- **Gestión de Dependencias:** `pip` con `requirements.txt`
- **Entorno de Desarrollo:** `venv` (entorno virtual de Python)

### 2.2. Librerías Clave
- `requests`: Para la comunicación con la API de NewsAPI.
- `pandas`: Para la estructuración y manipulación de datos en DataFrames.
- `python-dotenv`: Para la gestión segura de claves de API mediante variables de entorno.
- **NLP y Análisis de Sentimiento:**
    - `transformers` (de Hugging Face): El núcleo del análisis de sentimiento. Utiliza el modelo pre-entrenado `pysentimiento/robertuito-sentiment-analysis`, una implementación de RoBERTa optimizada para español.
    - `torch`: Framework de backend requerido por la librería `transformers`.
    - `nltk`: Utilizado para la tokenización de oraciones, una dependencia de `sumy`.
- **Resumen de Texto:**
    - `sumy`: Librería para generar resúmenes de texto extractivos. Se utiliza el algoritmo LSA (Latent Semantic Analysis).
- **Visualización y Exportación:**
    - `matplotlib` & `seaborn`: Para la generación de gráficos de distribución de sentimiento.
    - `wordcloud` (Opcional, en dependencias): Para la futura creación de nubes de palabras.

### 2.3. Estructura de Ficheros
El proyecto sigue una estructura modular para separar responsabilidades:
- **`analizador_noticias/`**
    - **`data/`**: Destinada a almacenar archivos temporales o noticias descargadas (actualmente sin uso).
    - **`reports/`**: Directorio de salida donde se guardan todos los artefactos generados (imágenes `.png` y reportes `.csv`).
    - **`src/`**: Contiene toda la lógica de la aplicación, separada en módulos:
        - `fetcher.py`: Responsable de la recolección de noticias desde NewsAPI.
        - `analyzer.py`: **(Componente clave)** Carga el modelo Transformer y realiza el análisis de sentimiento.
        - `summarizer.py`: Genera los resúmenes de texto.
        - `visualizer.py`: Crea los gráficos de sentimiento.
        - `exporter.py`: Exporta los resultados a CSV.
    - `app.py`: El orquestador principal. Importa los módulos de `src/` y ejecuta el pipeline completo.
    - `requirements.txt`: Lista de todas las dependencias del proyecto.
    - `.env`: **(Crítico, local)** Archivo para almacenar la clave de API (no versionado en Git).
    - `.gitignore`: Especifica los archivos y directorios a ignorar por Git.

---

## 3. Guía de Instalación y Ejecución

1.  **Clonar el Repositorio:**
    ```bash
    git clone <URL_DEL_REPOSITORIO>
    cd analizador_noticias
    ```

2.  **Configurar el Entorno (Python 3.11):**
    Asegúrate de tener Python 3.11 instalado.
    ```bash
    # Crear el entorno virtual
    python -m venv .venv

    # Activar el entorno (PowerShell en Windows)
    .venv\Scripts\Activate.ps1
    ```

3.  **Instalar Dependencias:**
    ```bash
    pip install -r requirements.txt
    ```

4.  **Configurar la Clave de API:**
    Crea un archivo llamado `.env` en la raíz del proyecto y añade tu clave de NewsAPI:
    ```
    NEWS_API_KEY=tu_clave_aqui
    ```

5.  **Ejecutar la Aplicación:**
    ```bash
    python app.py
    ```

---

## 4. Puntos a Tener en Cuenta

-   **Primera Ejecución:** La primera vez que se ejecute la aplicación, se descargarán automáticamente los paquetes `punkt` y `punkt_tab` de NLTK, y el modelo de `transformers` (`robertuito`), que pesa aproximadamente 435 MB. Este proceso es único y puede tardar varios minutos.
-   **Análisis de Sentimiento:** El modelo `robertuito` es significativamente más preciso que alternativas simples como TextBlob, ya que es sensible al contexto. Sin embargo, el análisis de sentimiento es una tarea compleja y los resultados deben interpretarse como una aproximación de alta precisión, no como una verdad absoluta.
-   **Salidas (Outputs):** Todos los archivos generados (gráficos y CSVs) se guardan en la carpeta `/reports` y se nombran con un timestamp para evitar sobrescrituras.
